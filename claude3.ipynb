{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T21:15:37.972164435Z",
     "start_time": "2024-03-06T21:15:37.971722496Z"
    }
   },
   "id": "e799c0ffb4902f57",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from griptape.structures import Agent\n",
    "from griptape.drivers import AmazonBedrockPromptDriver, BedrockClaudePromptModelDriver, BedrockClaude3PromptModelDriver\n",
    "from griptape.rules import Rule\n",
    "from griptape.config import StructureConfig, StructureGlobalDriversConfig\n",
    "import boto3\n",
    "\n",
    "# Create a session using a specific profile\n",
    "session = boto3.Session(profile_name=\"test-us-east-1\")\n",
    "agent = Agent(\n",
    "    config=StructureConfig(\n",
    "        global_drivers=StructureGlobalDriversConfig(\n",
    "            prompt_driver=AmazonBedrockPromptDriver(\n",
    "                model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                session=session,\n",
    "                prompt_model_driver=BedrockClaude3PromptModelDriver(),\n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    "    rules=[\n",
    "        Rule(\n",
    "            value=\"You are a customer service agent that is classifying emails by type. I want you to give your answer and then explain it.\"\n",
    "        )\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T21:15:40.792203138Z",
     "start_time": "2024-03-06T21:15:38.213472296Z"
    }
   },
   "id": "e2816bdec0454df8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[2;36m[03/06/24 22:15:40]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m PromptTask cb0d406bbf304e34a45e61ba2523cc64                                           \n\u001B[2;36m                    \u001B[0m         Input: hallo claude v3, how are you?                                                  \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/06/24 22:15:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> PromptTask cb0d406bbf304e34a45e61ba2523cc64                                           \n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Input: hallo claude v3, how are you?                                                  \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[2;36m[03/06/24 22:15:44]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m PromptTask cb0d406bbf304e34a45e61ba2523cc64                                           \n\u001B[2;36m                    \u001B[0m         Output: Email type: Greeting                                                          \n\u001B[2;36m                    \u001B[0m                                                                                               \n\u001B[2;36m                    \u001B[0m         Explanation: This email is a simple greeting, asking how I am doing. It does not      \n\u001B[2;36m                    \u001B[0m         contain any specific request or issue, just a friendly greeting. As a customer service\n\u001B[2;36m                    \u001B[0m         agent, I would classify this type of email as a \u001B[32m\"Greeting.\"\u001B[0m                           \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/06/24 22:15:44] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> PromptTask cb0d406bbf304e34a45e61ba2523cc64                                           \n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Output: Email type: Greeting                                                          \n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                               \n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Explanation: This email is a simple greeting, asking how I am doing. It does not      \n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         contain any specific request or issue, just a friendly greeting. As a customer service\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         agent, I would classify this type of email as a <span style=\"color: #008000; text-decoration-color: #008000\">\"Greeting.\"</span>                           \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Agent(id='065a98f5ae2c49efb8f296ddc370e41b', _stream=None, _prompt_driver=None, _embedding_driver=None, config=StructureConfig(type='StructureConfig', global_drivers=StructureGlobalDriversConfig(type='StructureGlobalDriversConfig', prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), image_generation_driver=DummyImageGenerationDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyImageGenerationDriver', structure=None, model=NOTHING), image_query_driver=DummyImageQueryDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyImageQueryDriver', structure=None, model=NOTHING), embedding_driver=DummyEmbeddingDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyEmbeddingDriver', tokenizer=None, chunker=NOTHING, model=NOTHING), vector_store_driver=DummyVectorStoreDriver(type='DummyVectorStoreDriver', futures_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7f09f9f7ddd0>, embedding_driver=DummyEmbeddingDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyEmbeddingDriver', tokenizer=None, chunker=NOTHING, model=NOTHING)), conversation_memory_driver=None), task_memory=StructureTaskMemoryConfig(type='StructureTaskMemoryConfig', query_engine=StructureTaskMemoryQueryEngineConfig(type='StructureTaskMemoryQueryEngineConfig', prompt_driver=DummyPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='DummyPromptDriver', temperature=0.1, max_tokens=None, structure=None, prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), stream=False, model=NOTHING, tokenizer=DummyTokenizer(stop_sequences=['<|Response|>'], max_tokens=0)), vector_store_driver=DummyVectorStoreDriver(type='DummyVectorStoreDriver', futures_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7f09f994db90>, embedding_driver=DummyEmbeddingDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyEmbeddingDriver', tokenizer=None, chunker=NOTHING, model=NOTHING))), extraction_engine=StructureTaskMemoryExtractionEngineConfig(type='StructureTaskMemoryExtractionEngineConfig', csv=StructureTaskMemoryExtractionEngineCsvConfig(type='StructureTaskMemoryExtractionEngineCsvConfig', prompt_driver=DummyPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='DummyPromptDriver', temperature=0.1, max_tokens=None, structure=None, prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), stream=False, model=NOTHING, tokenizer=DummyTokenizer(stop_sequences=['<|Response|>'], max_tokens=0))), json=StructureTaskMemoryExtractionEngineJsonConfig(type='StructureTaskMemoryExtractionEngineJsonConfig', prompt_driver=DummyPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='DummyPromptDriver', temperature=0.1, max_tokens=None, structure=None, prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), stream=False, model=NOTHING, tokenizer=DummyTokenizer(stop_sequences=['<|Response|>'], max_tokens=0)))), summary_engine=StructureTaskMemorySummaryEngineConfig(type='StructureTaskMemorySummaryEngineConfig', prompt_driver=DummyPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='DummyPromptDriver', temperature=0.1, max_tokens=None, structure=None, prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), stream=False, model=NOTHING, tokenizer=DummyTokenizer(stop_sequences=['<|Response|>'], max_tokens=0))))), rulesets=[], rules=[Rule(value='You are a customer service agent that is classifying emails by type. I want you to give your answer and then explain it.')], tasks=[PromptTask(id='cb0d406bbf304e34a45e61ba2523cc64', state=<State.FINISHED: 3>, parent_ids=[], child_ids=[], max_meta_memory_entries=20, context={}, rulesets=[], rules=[], structure=..., _input='{{ args[0] }}', _prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), generate_system_template=<bound method PromptTask.default_system_template_generator of ...>, output=TextArtifact(type='TextArtifact', id='6769372a6ad94ba7b9e2039af464a107', name='6769372a6ad94ba7b9e2039af464a107', value='Email type: Greeting\\n\\nExplanation: This email is a simple greeting, asking how I am doing. It does not contain any specific request or issue, just a friendly greeting. As a customer service agent, I would classify this type of email as a \"Greeting.\"', encoding='utf-8', encoding_error_handler='strict', _embedding=[]))], custom_logger=None, logger_level=20, event_listeners=[], conversation_memory=ConversationMemory(type='ConversationMemory', driver=None, runs=[Run(type='Run', id='39e4968296c648b387012eece14c4880', input='hallo claude v3, how are you?', output='Email type: Greeting\\n\\nExplanation: This email is a simple greeting, asking how I am doing. It does not contain any specific request or issue, just a friendly greeting. As a customer service agent, I would classify this type of email as a \"Greeting.\"')], structure=..., autoload=True, autoprune=True, max_runs=None), task_memory=TaskMemory(allowlist=None, denylist=None, name='TaskMemory', artifact_storages={<class 'griptape.artifacts.text_artifact.TextArtifact'>: TextArtifactStorage(query_engine=VectorQueryEngine(answer_token_offset=400, vector_store_driver=DummyVectorStoreDriver(type='DummyVectorStoreDriver', futures_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7f09f994db90>, embedding_driver=DummyEmbeddingDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, ignored_exception_types=(), type='DummyEmbeddingDriver', tokenizer=None, chunker=NOTHING, model=NOTHING)), prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), template_generator=J2(template_name='engines/query/vector_query.j2', templates_dir='/home/robin/Documents/griptape-fork/griptape/templates', environment=<jinja2.environment.Environment object at 0x7f09f994e210>)), summary_engine=PromptSummaryEngine(chunk_joiner='\\n\\n', max_token_multiplier=0.5, template_generator=J2(template_name='engines/summary/prompt_summary.j2', templates_dir='/home/robin/Documents/griptape-fork/griptape/templates', environment=<jinja2.environment.Environment object at 0x7f09f994e450>), prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), chunker=TextChunker(separators=[ChunkSeparator(value='\\n\\n', is_prefix=False), ChunkSeparator(value='\\n', is_prefix=False), ChunkSeparator(value='. ', is_prefix=False), ChunkSeparator(value='! ', is_prefix=False), ChunkSeparator(value='? ', is_prefix=False), ChunkSeparator(value=' ', is_prefix=False)], tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), max_tokens=50000)), csv_extraction_engine=CsvExtractionEngine(max_token_multiplier=0.5, chunk_joiner='\\n\\n', prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), chunker=TextChunker(separators=[ChunkSeparator(value='\\n\\n', is_prefix=False), ChunkSeparator(value='\\n', is_prefix=False), ChunkSeparator(value='. ', is_prefix=False), ChunkSeparator(value='! ', is_prefix=False), ChunkSeparator(value='? ', is_prefix=False), ChunkSeparator(value=' ', is_prefix=False)], tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), max_tokens=50000), template_generator=J2(template_name='engines/extraction/csv_extraction.j2', templates_dir='/home/robin/Documents/griptape-fork/griptape/templates', environment=<jinja2.environment.Environment object at 0x7f09f994e6d0>)), json_extraction_engine=JsonExtractionEngine(max_token_multiplier=0.5, chunk_joiner='\\n\\n', prompt_driver=AmazonBedrockPromptDriver(min_retry_delay=2, max_retry_delay=10, max_attempts=10, after_hook=<function ExponentialBackoffMixin.<lambda> at 0x7f0a2eada980>, type='AmazonBedrockPromptDriver', temperature=0.1, max_tokens=None, structure=..., prompt_stack_to_string=<bound method BasePromptDriver.default_prompt_stack_to_string_converter of ...>, ignored_exception_types=(<class 'ImportError'>, <class 'ValueError'>), model='anthropic.claude-3-sonnet-20240229-v1:0', tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_model_driver=BedrockClaude3PromptModelDriver(type='BedrockClaude3PromptModelDriver', supports_streaming=True, max_tokens=1024, _tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), prompt_driver=...), stream=False, session=Session(region_name='us-east-1'), bedrock_client=<botocore.client.BedrockRuntime object at 0x7f09fa192e90>), chunker=TextChunker(separators=[ChunkSeparator(value='\\n\\n', is_prefix=False), ChunkSeparator(value='\\n', is_prefix=False), ChunkSeparator(value='. ', is_prefix=False), ChunkSeparator(value='! ', is_prefix=False), ChunkSeparator(value='? ', is_prefix=False), ChunkSeparator(value=' ', is_prefix=False)], tokenizer=BedrockClaudeTokenizer(stop_sequences=['<|Response|>'], model='anthropic.claude-3-sonnet-20240229-v1:0', max_tokens=100000, client=<anthropic.Anthropic object at 0x7f09fa8e0a10>), max_tokens=50000), template_generator=J2(template_name='engines/extraction/json_extraction.j2', templates_dir='/home/robin/Documents/griptape-fork/griptape/templates', environment=<jinja2.environment.Environment object at 0x7f09f994e9d0>))), <class 'griptape.artifacts.blob_artifact.BlobArtifact'>: BlobArtifactStorage(blobs={})}, namespace_storage={}, namespace_metadata={}), meta_memory=MetaMemory(entries=[]), _execution_args=('hallo claude v3, how are you?',), _logger=<Logger griptape (INFO)>, input_template='{{ args[0] }}', tools=[], max_meta_memory_entries=20)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"hallo claude v3, how are you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T21:15:44.229661498Z",
     "start_time": "2024-03-06T21:15:40.791540204Z"
    }
   },
   "id": "23af32056ca69f7e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock-runtime\")\n",
    "body = json.dumps({\n",
    "  \"max_tokens\": 256,\n",
    "  \"messages\": [{\"role\": \"user\", \"content\": \"Hello, world\"}],\n",
    "  \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "})\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body.get(\"content\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "277c444d7ded3ecc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
